At times we need to fetch some datağŸ“ˆ from our GitHub like details about the pull requestsğŸ©¹ to some of our repositories in an open sourceğŸ¤ program.

Larger the data, the more cumbersomeğŸ˜ª it becomes to fetch, analyze and derive the desired inference

What if we could automateğŸ¤– it?

Well, using a simple pythonğŸ script with a GraphQLâš› query can save the day for us!

- I assume you have Anaconda installed in your operating system and set to path. If not, please visit this [link](https://docs.anaconda.com/anaconda/install/) and do it

- Clone or download this repository â¬

- Open the Terminal ğŸ±â€ğŸ’»

- Move inside ğŸ‘‰ the your cloned copy of the repo

`cd GitKundli`

- Now make sure you have all the dependenciesğŸ§±

`pip install -r requirements.txt`

- Time to run our app

`streamlit run app.py`

- Open `http://localhost:8502` or the link displayed in the terminal where the streamlit app is running on your local server

- Visit this [link](https://github.com/settings/tokens) and Click on `Generate new token`

- Initially select all the options. [ Note: Later on you can come back, delete this token and generate a new one with only the permissions you think are necessary]

- Don't forget to give a name to the token ( say `gitkundli` )

- Copy the alphanumeric value of the taken [and save it in a text file for future reference. Remember you can only access this once on GitHub]
- Return back your hosted app

- Open Specific Pages, Give the Token, Some related Information, Make use of the output!

- Now let's run our script and store our results in a csv file `python gitkundli.py`

